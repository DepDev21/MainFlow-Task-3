# ðŸ“Œ Import libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.decomposition import PCA

# ðŸ“Œ Load dataset
df = pd.read_csv("customer_data.csv")
print("First 5 rows of dataset:\n", df.head())

# ðŸ“Œ Inspect dataset
print("\nShape:", df.shape)
print("Missing values:\n", df.isnull().sum())
print("Duplicates:", df.duplicated().sum())
print("Data types:\n", df.dtypes)
print("\nSummary statistics:\n", df.describe())

# ðŸ“Œ Standardize data
X = df[['Age', 'Annual Income', 'Spending Score']]
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ðŸ“Œ Elbow Method
wcss = []
K = range(1, 8)

for k in K:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(X_scaled)
    wcss.append(kmeans.inertia_)

plt.figure(figsize=(7,5))
plt.plot(K, wcss, 'bo-')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS')
plt.title('Elbow Method to determine optimal k')
plt.show()

# ðŸ“Œ Silhouette scores (optional)
for k in range(2, 6):
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    labels = kmeans.fit_predict(X_scaled)
    score = silhouette_score(X_scaled, labels)
    print(f"Silhouette Score for {k} clusters: {score:.3f}")

# ðŸ“Œ Apply KMeans (choose k = 3 for this example)
optimal_k = 3
kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
df['Cluster'] = kmeans.fit_predict(X_scaled)

print("\nClustered dataset:\n", df.head())

# ðŸ“Œ PCA for 2D visualization
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

plt.figure(figsize=(7,5))
sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=df['Cluster'], palette='Set1', s=100)
plt.title('Customer Segments (PCA Reduced)')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.show()

# ðŸ“Œ Pair plot
sns.pairplot(df, hue='Cluster', vars=['Age', 'Annual Income', 'Spending Score'], palette='Set1')
plt.show()

# ðŸ“Œ Centroids in original scale
centroids = scaler.inverse_transform(kmeans.cluster_centers_)
for i, center in enumerate(centroids):
    print(f"Cluster {i}: Age={center[0]:.1f}, Income={center[1]:.1f}, Spending Score={center[2]:.1f}")

# ðŸ“Œ Recommendations / insights
print("\n--- Cluster Insights & Recommendations ---")
for i in range(optimal_k):
    seg = df[df['Cluster'] == i]
    print(f"\nCluster {i} Summary:")
    print(f" Avg Age: {seg['Age'].mean():.1f}")
    print(f" Avg Annual Income: {seg['Annual Income'].mean():.1f}")
    print(f" Avg Spending Score: {seg['Spending Score'].mean():.1f}")

print("\nâœ… Target clusters with high income & high spending score for premium offers.")
print("âœ… Consider loyalty programs for high spenders.")
print("âœ… Tailor marketing campaigns by age and spending patterns.")
